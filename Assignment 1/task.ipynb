{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "# plt.style.use('dark_background')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# Regression data path\n",
    "BITRATE_PREDICTION_TRAIN = 'bitrate_prediction/bitrate_train.csv'\n",
    "BITRATE_PREDICTION_TEST = 'bitrate_prediction/bitrate_test.csv'\n",
    "\n",
    "# Classification data path\n",
    "STREAM_CLASSIFICATION_TRAIN = 'stream_quality_data/train_data.csv'\n",
    "STREAM_CLASSIFICATION_TEST = 'stream_quality_data/test_data.csv'\n",
    "\n",
    "# read csv\n",
    "bitrate_reg_train = pd.read_csv(BITRATE_PREDICTION_TRAIN)\n",
    "bitrate_reg_test = pd.read_csv(BITRATE_PREDICTION_TEST)\n",
    "\n",
    "stream_class_train = pd.read_csv(STREAM_CLASSIFICATION_TRAIN)\n",
    "stream_class_test = pd.read_csv(STREAM_CLASSIFICATION_TEST)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitrate train data shape:  (379021, 10)\n",
      "bitrate test data shape:  (228145, 10)\n",
      "stream train data shape:  (406572, 12)\n",
      "stream test data shape:  (243596, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"bitrate train data shape: \", bitrate_reg_train.shape)\n",
    "print(\"bitrate test data shape: \", bitrate_reg_test.shape)\n",
    "\n",
    "print(\"stream train data shape: \", stream_class_train.shape)\n",
    "print(\"stream test data shape: \", stream_class_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "fps_mean               0\nfps_std                0\nrtt_mean               0\nrtt_std                0\ndropped_frames_mean    0\ndropped_frames_std     0\ndropped_frames_max     0\nbitrate_mean           0\nbitrate_std            0\ntarget                 0\ndtype: int64"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitrate_reg_train.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "fps_mean               0\nfps_std                0\nfps_lags               0\nrtt_mean               0\nrtt_std                0\ndropped_frames_mean    0\ndropped_frames_std     0\ndropped_frames_max     0\nauto_bitrate_state     0\nauto_fec_state         0\nauto_fec_mean          0\nstream_quality         0\ndtype: int64"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_class_train.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x2899ef3a0>",
      "text/html": "<style type=\"text/css\">\n#T_e4701_row0_col1 {\n  width: 10em;\n  background: linear-gradient(90deg, #606ff2 0.5%, transparent 0.5%);\n}\n#T_e4701_row0_col2, #T_e4701_row1_col2, #T_e4701_row1_col5, #T_e4701_row3_col5, #T_e4701_row4_col2, #T_e4701_row4_col5, #T_e4701_row5_col2, #T_e4701_row5_col5, #T_e4701_row6_col2, #T_e4701_row6_col5 {\n  background-color: #fff7fb;\n  color: #000000;\n}\n#T_e4701_row0_col5, #T_e4701_row2_col5 {\n  background-color: #fef6fb;\n  color: #000000;\n}\n#T_e4701_row1_col1, #T_e4701_row4_col1, #T_e4701_row5_col1, #T_e4701_row6_col1 {\n  width: 10em;\n  background: linear-gradient(90deg, #606ff2 0.0%, transparent 0.0%);\n}\n#T_e4701_row2_col1 {\n  width: 10em;\n  background: linear-gradient(90deg, #606ff2 0.7%, transparent 0.7%);\n}\n#T_e4701_row2_col2, #T_e4701_row3_col2 {\n  background-color: #fdf5fa;\n  color: #000000;\n}\n#T_e4701_row3_col1 {\n  width: 10em;\n  background: linear-gradient(90deg, #606ff2 0.2%, transparent 0.2%);\n}\n#T_e4701_row7_col1 {\n  width: 10em;\n  background: linear-gradient(90deg, #606ff2 99.9%, transparent 99.9%);\n}\n#T_e4701_row7_col2, #T_e4701_row7_col5, #T_e4701_row9_col2, #T_e4701_row9_col5 {\n  background-color: #023858;\n  color: #f1f1f1;\n}\n#T_e4701_row8_col1 {\n  width: 10em;\n  background: linear-gradient(90deg, #606ff2 21.3%, transparent 21.3%);\n}\n#T_e4701_row8_col2 {\n  background-color: #c5cce3;\n  color: #000000;\n}\n#T_e4701_row8_col5 {\n  background-color: #e0deed;\n  color: #000000;\n}\n#T_e4701_row9_col1 {\n  width: 10em;\n  background: linear-gradient(90deg, #606ff2 100.0%, transparent 100.0%);\n}\n</style>\n<table id=\"T_e4701\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_e4701_level0_col0\" class=\"col_heading level0 col0\" >count</th>\n      <th id=\"T_e4701_level0_col1\" class=\"col_heading level0 col1\" >mean</th>\n      <th id=\"T_e4701_level0_col2\" class=\"col_heading level0 col2\" >std</th>\n      <th id=\"T_e4701_level0_col3\" class=\"col_heading level0 col3\" >min</th>\n      <th id=\"T_e4701_level0_col4\" class=\"col_heading level0 col4\" >25%</th>\n      <th id=\"T_e4701_level0_col5\" class=\"col_heading level0 col5\" >50%</th>\n      <th id=\"T_e4701_level0_col6\" class=\"col_heading level0 col6\" >75%</th>\n      <th id=\"T_e4701_level0_col7\" class=\"col_heading level0 col7\" >max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_e4701_level0_row0\" class=\"row_heading level0 row0\" >fps_mean</th>\n      <td id=\"T_e4701_row0_col0\" class=\"data row0 col0\" >379021.000000</td>\n      <td id=\"T_e4701_row0_col1\" class=\"data row0 col1\" >35.231127</td>\n      <td id=\"T_e4701_row0_col2\" class=\"data row0 col2\" >10.975010</td>\n      <td id=\"T_e4701_row0_col3\" class=\"data row0 col3\" >10.000000</td>\n      <td id=\"T_e4701_row0_col4\" class=\"data row0 col4\" >28.800000</td>\n      <td id=\"T_e4701_row0_col5\" class=\"data row0 col5\" >30.000000</td>\n      <td id=\"T_e4701_row0_col6\" class=\"data row0 col6\" >43.600000</td>\n      <td id=\"T_e4701_row0_col7\" class=\"data row0 col7\" >125.800000</td>\n    </tr>\n    <tr>\n      <th id=\"T_e4701_level0_row1\" class=\"row_heading level0 row1\" >fps_std</th>\n      <td id=\"T_e4701_row1_col0\" class=\"data row1 col0\" >379021.000000</td>\n      <td id=\"T_e4701_row1_col1\" class=\"data row1 col1\" >1.725705</td>\n      <td id=\"T_e4701_row1_col2\" class=\"data row1 col2\" >2.505942</td>\n      <td id=\"T_e4701_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n      <td id=\"T_e4701_row1_col4\" class=\"data row1 col4\" >0.316228</td>\n      <td id=\"T_e4701_row1_col5\" class=\"data row1 col5\" >0.942809</td>\n      <td id=\"T_e4701_row1_col6\" class=\"data row1 col6\" >2.233582</td>\n      <td id=\"T_e4701_row1_col7\" class=\"data row1 col7\" >307.167273</td>\n    </tr>\n    <tr>\n      <th id=\"T_e4701_level0_row2\" class=\"row_heading level0 row2\" >rtt_mean</th>\n      <td id=\"T_e4701_row2_col0\" class=\"data row2 col0\" >379021.000000</td>\n      <td id=\"T_e4701_row2_col1\" class=\"data row2 col1\" >49.623858</td>\n      <td id=\"T_e4701_row2_col2\" class=\"data row2 col2\" >94.781098</td>\n      <td id=\"T_e4701_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n      <td id=\"T_e4701_row2_col4\" class=\"data row2 col4\" >14.300000</td>\n      <td id=\"T_e4701_row2_col5\" class=\"data row2 col5\" >32.200000</td>\n      <td id=\"T_e4701_row2_col6\" class=\"data row2 col6\" >55.900000</td>\n      <td id=\"T_e4701_row2_col7\" class=\"data row2 col7\" >12898.400000</td>\n    </tr>\n    <tr>\n      <th id=\"T_e4701_level0_row3\" class=\"row_heading level0 row3\" >rtt_std</th>\n      <td id=\"T_e4701_row3_col0\" class=\"data row3 col0\" >379021.000000</td>\n      <td id=\"T_e4701_row3_col1\" class=\"data row3 col1\" >12.763672</td>\n      <td id=\"T_e4701_row3_col2\" class=\"data row3 col2\" >112.684460</td>\n      <td id=\"T_e4701_row3_col3\" class=\"data row3 col3\" >0.000000</td>\n      <td id=\"T_e4701_row3_col4\" class=\"data row3 col4\" >0.699206</td>\n      <td id=\"T_e4701_row3_col5\" class=\"data row3 col5\" >1.433721</td>\n      <td id=\"T_e4701_row3_col6\" class=\"data row3 col6\" >4.948625</td>\n      <td id=\"T_e4701_row3_col7\" class=\"data row3 col7\" >40721.933293</td>\n    </tr>\n    <tr>\n      <th id=\"T_e4701_level0_row4\" class=\"row_heading level0 row4\" >dropped_frames_mean</th>\n      <td id=\"T_e4701_row4_col0\" class=\"data row4 col0\" >379021.000000</td>\n      <td id=\"T_e4701_row4_col1\" class=\"data row4 col1\" >0.180451</td>\n      <td id=\"T_e4701_row4_col2\" class=\"data row4 col2\" >1.732890</td>\n      <td id=\"T_e4701_row4_col3\" class=\"data row4 col3\" >0.000000</td>\n      <td id=\"T_e4701_row4_col4\" class=\"data row4 col4\" >0.000000</td>\n      <td id=\"T_e4701_row4_col5\" class=\"data row4 col5\" >0.000000</td>\n      <td id=\"T_e4701_row4_col6\" class=\"data row4 col6\" >0.000000</td>\n      <td id=\"T_e4701_row4_col7\" class=\"data row4 col7\" >540.000000</td>\n    </tr>\n    <tr>\n      <th id=\"T_e4701_level0_row5\" class=\"row_heading level0 row5\" >dropped_frames_std</th>\n      <td id=\"T_e4701_row5_col0\" class=\"data row5 col0\" >379021.000000</td>\n      <td id=\"T_e4701_row5_col1\" class=\"data row5 col1\" >0.469548</td>\n      <td id=\"T_e4701_row5_col2\" class=\"data row5 col2\" >3.157866</td>\n      <td id=\"T_e4701_row5_col3\" class=\"data row5 col3\" >0.000000</td>\n      <td id=\"T_e4701_row5_col4\" class=\"data row5 col4\" >0.000000</td>\n      <td id=\"T_e4701_row5_col5\" class=\"data row5 col5\" >0.000000</td>\n      <td id=\"T_e4701_row5_col6\" class=\"data row5 col6\" >0.000000</td>\n      <td id=\"T_e4701_row5_col7\" class=\"data row5 col7\" >202.385770</td>\n    </tr>\n    <tr>\n      <th id=\"T_e4701_level0_row6\" class=\"row_heading level0 row6\" >dropped_frames_max</th>\n      <td id=\"T_e4701_row6_col0\" class=\"data row6 col0\" >379021.000000</td>\n      <td id=\"T_e4701_row6_col1\" class=\"data row6 col1\" >1.450719</td>\n      <td id=\"T_e4701_row6_col2\" class=\"data row6 col2\" >9.670928</td>\n      <td id=\"T_e4701_row6_col3\" class=\"data row6 col3\" >0.000000</td>\n      <td id=\"T_e4701_row6_col4\" class=\"data row6 col4\" >0.000000</td>\n      <td id=\"T_e4701_row6_col5\" class=\"data row6 col5\" >0.000000</td>\n      <td id=\"T_e4701_row6_col6\" class=\"data row6 col6\" >0.000000</td>\n      <td id=\"T_e4701_row6_col7\" class=\"data row6 col7\" >640.000000</td>\n    </tr>\n    <tr>\n      <th id=\"T_e4701_level0_row7\" class=\"row_heading level0 row7\" >bitrate_mean</th>\n      <td id=\"T_e4701_row7_col0\" class=\"data row7 col0\" >379021.000000</td>\n      <td id=\"T_e4701_row7_col1\" class=\"data row7 col1\" >7516.585502</td>\n      <td id=\"T_e4701_row7_col2\" class=\"data row7 col2\" >6073.992189</td>\n      <td id=\"T_e4701_row7_col3\" class=\"data row7 col3\" >0.000000</td>\n      <td id=\"T_e4701_row7_col4\" class=\"data row7 col4\" >2773.300000</td>\n      <td id=\"T_e4701_row7_col5\" class=\"data row7 col5\" >6287.200000</td>\n      <td id=\"T_e4701_row7_col6\" class=\"data row7 col6\" >10187.200000</td>\n      <td id=\"T_e4701_row7_col7\" class=\"data row7 col7\" >64913.500000</td>\n    </tr>\n    <tr>\n      <th id=\"T_e4701_level0_row8\" class=\"row_heading level0 row8\" >bitrate_std</th>\n      <td id=\"T_e4701_row8_col0\" class=\"data row8 col0\" >379021.000000</td>\n      <td id=\"T_e4701_row8_col1\" class=\"data row8 col1\" >1603.487501</td>\n      <td id=\"T_e4701_row8_col2\" class=\"data row8 col2\" >1721.021623</td>\n      <td id=\"T_e4701_row8_col3\" class=\"data row8 col3\" >0.000000</td>\n      <td id=\"T_e4701_row8_col4\" class=\"data row8 col4\" >383.683550</td>\n      <td id=\"T_e4701_row8_col5\" class=\"data row8 col5\" >1112.710010</td>\n      <td id=\"T_e4701_row8_col6\" class=\"data row8 col6\" >2241.848801</td>\n      <td id=\"T_e4701_row8_col7\" class=\"data row8 col7\" >26908.532303</td>\n    </tr>\n    <tr>\n      <th id=\"T_e4701_level0_row9\" class=\"row_heading level0 row9\" >target</th>\n      <td id=\"T_e4701_row9_col0\" class=\"data row9 col0\" >379021.000000</td>\n      <td id=\"T_e4701_row9_col1\" class=\"data row9 col1\" >7525.396231</td>\n      <td id=\"T_e4701_row9_col2\" class=\"data row9 col2\" >6070.817736</td>\n      <td id=\"T_e4701_row9_col3\" class=\"data row9 col3\" >0.000000</td>\n      <td id=\"T_e4701_row9_col4\" class=\"data row9 col4\" >2785.000000</td>\n      <td id=\"T_e4701_row9_col5\" class=\"data row9 col5\" >6296.000000</td>\n      <td id=\"T_e4701_row9_col6\" class=\"data row9 col6\" >10192.000000</td>\n      <td id=\"T_e4701_row9_col7\" class=\"data row9 col7\" >64913.000000</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitrate_reg_train.describe().T.style.bar(\n",
    "    subset=['mean'], color='#606ff2'\n",
    ").background_gradient(\n",
    "    subset=['std'], cmap='PuBu'\n",
    ").background_gradient(\n",
    "    subset=['50%'], cmap='PuBu'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x285056610>",
      "text/html": "<style type=\"text/css\">\n#T_df755_row0_col1, #T_df755_row1_col1, #T_df755_row2_col1, #T_df755_row3_col1, #T_df755_row4_col1, #T_df755_row8_col1, #T_df755_row9_col1 {\n  width: 10em;\n  background: linear-gradient(90deg, #606ff2 0.0%, transparent 0.0%);\n}\n#T_df755_row0_col2, #T_df755_row1_col2, #T_df755_row2_col2, #T_df755_row2_col5, #T_df755_row3_col2, #T_df755_row4_col2, #T_df755_row5_col5, #T_df755_row6_col5, #T_df755_row7_col5, #T_df755_row8_col2, #T_df755_row9_col2, #T_df755_row9_col5 {\n  background-color: #fff7fb;\n  color: #000000;\n}\n#T_df755_row0_col5 {\n  background-color: #4295c3;\n  color: #f1f1f1;\n}\n#T_df755_row1_col5 {\n  background-color: #fcf4fa;\n  color: #000000;\n}\n#T_df755_row3_col5 {\n  background-color: #2d8abd;\n  color: #f1f1f1;\n}\n#T_df755_row4_col5 {\n  background-color: #fbf3f9;\n  color: #000000;\n}\n#T_df755_row5_col1 {\n  width: 10em;\n  background: linear-gradient(90deg, #606ff2 91.4%, transparent 91.4%);\n}\n#T_df755_row5_col2 {\n  background-color: #034871;\n  color: #f1f1f1;\n}\n#T_df755_row6_col1 {\n  width: 10em;\n  background: linear-gradient(90deg, #606ff2 7.3%, transparent 7.3%);\n}\n#T_df755_row6_col2 {\n  background-color: #e0deed;\n  color: #000000;\n}\n#T_df755_row7_col1 {\n  width: 10em;\n  background: linear-gradient(90deg, #606ff2 100.0%, transparent 100.0%);\n}\n#T_df755_row7_col2, #T_df755_row8_col5 {\n  background-color: #023858;\n  color: #f1f1f1;\n}\n</style>\n<table id=\"T_df755\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_df755_level0_col0\" class=\"col_heading level0 col0\" >count</th>\n      <th id=\"T_df755_level0_col1\" class=\"col_heading level0 col1\" >mean</th>\n      <th id=\"T_df755_level0_col2\" class=\"col_heading level0 col2\" >std</th>\n      <th id=\"T_df755_level0_col3\" class=\"col_heading level0 col3\" >min</th>\n      <th id=\"T_df755_level0_col4\" class=\"col_heading level0 col4\" >25%</th>\n      <th id=\"T_df755_level0_col5\" class=\"col_heading level0 col5\" >50%</th>\n      <th id=\"T_df755_level0_col6\" class=\"col_heading level0 col6\" >75%</th>\n      <th id=\"T_df755_level0_col7\" class=\"col_heading level0 col7\" >max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_df755_level0_row0\" class=\"row_heading level0 row0\" >fps_mean</th>\n      <td id=\"T_df755_row0_col0\" class=\"data row0 col0\" >406572.000000</td>\n      <td id=\"T_df755_row0_col1\" class=\"data row0 col1\" >34.497561</td>\n      <td id=\"T_df755_row0_col2\" class=\"data row0 col2\" >11.625494</td>\n      <td id=\"T_df755_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n      <td id=\"T_df755_row0_col4\" class=\"data row0 col4\" >28.300000</td>\n      <td id=\"T_df755_row0_col5\" class=\"data row0 col5\" >30.000000</td>\n      <td id=\"T_df755_row0_col6\" class=\"data row0 col6\" >43.000000</td>\n      <td id=\"T_df755_row0_col7\" class=\"data row0 col7\" >127.100000</td>\n    </tr>\n    <tr>\n      <th id=\"T_df755_level0_row1\" class=\"row_heading level0 row1\" >fps_std</th>\n      <td id=\"T_df755_row1_col0\" class=\"data row1 col0\" >406572.000000</td>\n      <td id=\"T_df755_row1_col1\" class=\"data row1 col1\" >2.285486</td>\n      <td id=\"T_df755_row1_col2\" class=\"data row1 col2\" >3.708531</td>\n      <td id=\"T_df755_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n      <td id=\"T_df755_row1_col4\" class=\"data row1 col4\" >0.316228</td>\n      <td id=\"T_df755_row1_col5\" class=\"data row1 col5\" >0.994429</td>\n      <td id=\"T_df755_row1_col6\" class=\"data row1 col6\" >2.590581</td>\n      <td id=\"T_df755_row1_col7\" class=\"data row1 col7\" >312.540842</td>\n    </tr>\n    <tr>\n      <th id=\"T_df755_level0_row2\" class=\"row_heading level0 row2\" >fps_lags</th>\n      <td id=\"T_df755_row2_col0\" class=\"data row2 col0\" >406572.000000</td>\n      <td id=\"T_df755_row2_col1\" class=\"data row2 col1\" >0.183151</td>\n      <td id=\"T_df755_row2_col2\" class=\"data row2 col2\" >1.099384</td>\n      <td id=\"T_df755_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n      <td id=\"T_df755_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n      <td id=\"T_df755_row2_col5\" class=\"data row2 col5\" >0.000000</td>\n      <td id=\"T_df755_row2_col6\" class=\"data row2 col6\" >0.000000</td>\n      <td id=\"T_df755_row2_col7\" class=\"data row2 col7\" >10.000000</td>\n    </tr>\n    <tr>\n      <th id=\"T_df755_level0_row3\" class=\"row_heading level0 row3\" >rtt_mean</th>\n      <td id=\"T_df755_row3_col0\" class=\"data row3 col0\" >406572.000000</td>\n      <td id=\"T_df755_row3_col1\" class=\"data row3 col1\" >54.314400</td>\n      <td id=\"T_df755_row3_col2\" class=\"data row3 col2\" >133.872062</td>\n      <td id=\"T_df755_row3_col3\" class=\"data row3 col3\" >0.000000</td>\n      <td id=\"T_df755_row3_col4\" class=\"data row3 col4\" >14.100000</td>\n      <td id=\"T_df755_row3_col5\" class=\"data row3 col5\" >32.300000</td>\n      <td id=\"T_df755_row3_col6\" class=\"data row3 col6\" >57.100000</td>\n      <td id=\"T_df755_row3_col7\" class=\"data row3 col7\" >12898.400000</td>\n    </tr>\n    <tr>\n      <th id=\"T_df755_level0_row4\" class=\"row_heading level0 row4\" >rtt_std</th>\n      <td id=\"T_df755_row4_col0\" class=\"data row4 col0\" >406572.000000</td>\n      <td id=\"T_df755_row4_col1\" class=\"data row4 col1\" >19.525019</td>\n      <td id=\"T_df755_row4_col2\" class=\"data row4 col2\" >156.364337</td>\n      <td id=\"T_df755_row4_col3\" class=\"data row4 col3\" >0.000000</td>\n      <td id=\"T_df755_row4_col4\" class=\"data row4 col4\" >0.699206</td>\n      <td id=\"T_df755_row4_col5\" class=\"data row4 col5\" >1.490712</td>\n      <td id=\"T_df755_row4_col6\" class=\"data row4 col6\" >5.334375</td>\n      <td id=\"T_df755_row4_col7\" class=\"data row4 col7\" >40721.933293</td>\n    </tr>\n    <tr>\n      <th id=\"T_df755_level0_row5\" class=\"row_heading level0 row5\" >dropped_frames_mean</th>\n      <td id=\"T_df755_row5_col0\" class=\"data row5 col0\" >406572.000000</td>\n      <td id=\"T_df755_row5_col1\" class=\"data row5 col1\" >1730432.423986</td>\n      <td id=\"T_df755_row5_col2\" class=\"data row5 col2\" >49300910.708629</td>\n      <td id=\"T_df755_row5_col3\" class=\"data row5 col3\" >0.000000</td>\n      <td id=\"T_df755_row5_col4\" class=\"data row5 col4\" >0.000000</td>\n      <td id=\"T_df755_row5_col5\" class=\"data row5 col5\" >0.000000</td>\n      <td id=\"T_df755_row5_col6\" class=\"data row5 col6\" >0.000000</td>\n      <td id=\"T_df755_row5_col7\" class=\"data row5 col7\" >2097288600.000000</td>\n    </tr>\n    <tr>\n      <th id=\"T_df755_level0_row6\" class=\"row_heading level0 row6\" >dropped_frames_std</th>\n      <td id=\"T_df755_row6_col0\" class=\"data row6 col0\" >406572.000000</td>\n      <td id=\"T_df755_row6_col1\" class=\"data row6 col1\" >137827.870355</td>\n      <td id=\"T_df755_row6_col2\" class=\"data row6 col2\" >9229775.537018</td>\n      <td id=\"T_df755_row6_col3\" class=\"data row6 col3\" >0.000000</td>\n      <td id=\"T_df755_row6_col4\" class=\"data row6 col4\" >0.000000</td>\n      <td id=\"T_df755_row6_col5\" class=\"data row6 col5\" >0.000000</td>\n      <td id=\"T_df755_row6_col6\" class=\"data row6 col6\" >0.000000</td>\n      <td id=\"T_df755_row6_col7\" class=\"data row6 col7\" >996375136.438125</td>\n    </tr>\n    <tr>\n      <th id=\"T_df755_level0_row7\" class=\"row_heading level0 row7\" >dropped_frames_max</th>\n      <td id=\"T_df755_row7_col0\" class=\"data row7 col0\" >406572.000000</td>\n      <td id=\"T_df755_row7_col1\" class=\"data row7 col1\" >1893338.780248</td>\n      <td id=\"T_df755_row7_col2\" class=\"data row7 col2\" >52410034.996107</td>\n      <td id=\"T_df755_row7_col3\" class=\"data row7 col3\" >0.000000</td>\n      <td id=\"T_df755_row7_col4\" class=\"data row7 col4\" >0.000000</td>\n      <td id=\"T_df755_row7_col5\" class=\"data row7 col5\" >0.000000</td>\n      <td id=\"T_df755_row7_col6\" class=\"data row7 col6\" >0.000000</td>\n      <td id=\"T_df755_row7_col7\" class=\"data row7 col7\" >2097288600.000000</td>\n    </tr>\n    <tr>\n      <th id=\"T_df755_level0_row8\" class=\"row_heading level0 row8\" >auto_fec_mean</th>\n      <td id=\"T_df755_row8_col0\" class=\"data row8 col0\" >406572.000000</td>\n      <td id=\"T_df755_row8_col1\" class=\"data row8 col1\" >51.413536</td>\n      <td id=\"T_df755_row8_col2\" class=\"data row8 col2\" >34.836045</td>\n      <td id=\"T_df755_row8_col3\" class=\"data row8 col3\" >0.000000</td>\n      <td id=\"T_df755_row8_col4\" class=\"data row8 col4\" >50.000000</td>\n      <td id=\"T_df755_row8_col5\" class=\"data row8 col5\" >50.000000</td>\n      <td id=\"T_df755_row8_col6\" class=\"data row8 col6\" >50.000000</td>\n      <td id=\"T_df755_row8_col7\" class=\"data row8 col7\" >250.000000</td>\n    </tr>\n    <tr>\n      <th id=\"T_df755_level0_row9\" class=\"row_heading level0 row9\" >stream_quality</th>\n      <td id=\"T_df755_row9_col0\" class=\"data row9 col0\" >406572.000000</td>\n      <td id=\"T_df755_row9_col1\" class=\"data row9 col1\" >0.068460</td>\n      <td id=\"T_df755_row9_col2\" class=\"data row9 col2\" >0.252534</td>\n      <td id=\"T_df755_row9_col3\" class=\"data row9 col3\" >0.000000</td>\n      <td id=\"T_df755_row9_col4\" class=\"data row9 col4\" >0.000000</td>\n      <td id=\"T_df755_row9_col5\" class=\"data row9 col5\" >0.000000</td>\n      <td id=\"T_df755_row9_col6\" class=\"data row9 col6\" >0.000000</td>\n      <td id=\"T_df755_row9_col7\" class=\"data row9 col7\" >1.000000</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_class_train.describe().T.style.bar(\n",
    "    subset=['mean'], color='#606ff2'\n",
    ").background_gradient(\n",
    "    subset=['std'], cmap='PuBu'\n",
    ").background_gradient(\n",
    "    subset=['50%'], cmap='PuBu'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "        model: str,\n",
    "        x_train=False,\n",
    "        y_train=False,\n",
    "        x_test=False,\n",
    "        y_test=False,\n",
    "        metrics=None,\n",
    "        fit_model=False\n",
    ") -> tuple[Any, Any, Any]:\n",
    "    if metrics is None:\n",
    "        metrics = {\"r2_score\": r2_score, \"mse\": mean_squared_error}\n",
    "    if type(x_test) == bool or type(y_test) == bool:\n",
    "        x_test = x_train\n",
    "        y_test = y_train\n",
    "\n",
    "    if fit_model:\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    scores = {}\n",
    "    for t in metrics.keys():\n",
    "        scores.update({t: metrics[t](y_test, y_pred)})\n",
    "\n",
    "    return scores, model, y_pred\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self, estimator, threshold=0.5):\n",
    "        self.estimator = estimator\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.estimator.fit(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.estimator.predict_proba(x)[:, 0] < self.threshold\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {'threshold': self.threshold, 'subestimator': self.estimator}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "\n",
    "class Polynomial(BaseEstimator):\n",
    "    def __init__(self, degree=2, estimator=LinearRegression()):\n",
    "        self.poly_transform = None\n",
    "        self.degree = degree\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.poly_transform = PolynomialFeatures(self.degree).fit(X)\n",
    "        self.estimator.fit(self.poly_transform.transform(X), y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(self.poly_transform.transform(X))\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {'degree': self.degree,\n",
    "                'estimator': self.estimator}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self):\n",
    "        self.scaler = None\n",
    "\n",
    "    def regression_pipe(self, X_, y, fit_mode=False, final=True, show_shapes=True):\n",
    "        X = X_.copy()\n",
    "\n",
    "        if show_shapes:\n",
    "            print(f'Initial data shape: {X.shape}')\n",
    "\n",
    "        # dropping bitrate features\n",
    "        X.drop([\"bitrate_mean\", \"bitrate_std\"], inplace=True, axis=1)\n",
    "\n",
    "        # adding binary features\n",
    "        X['dropped_frames_occured'] = X['dropped_frames_mean'].apply(lambda x: np.int8(x > 0))\n",
    "        X['fps_std'] = X['fps_std'].apply(lambda x: x > 6)\n",
    "        X['fps_unstable'] = X['fps_std'].apply(lambda x: x > 5)\n",
    "        X['rtt_unstable'] = X['rtt_std'].apply(lambda x: x > 5)\n",
    "        X['fps_anomaly'] = X['fps_mean'].apply(lambda x: not (25 < x < 35))\n",
    "        X['rtt_anomaly'] = X['rtt_mean'].apply(lambda x: x > 50)\n",
    "\n",
    "        # adding logarithmic features\n",
    "        X[\"fps_std_log\"] = X[\"fps_std\"].apply(lambda x: np.log(x) if x > 2 else x)\n",
    "        X.drop([\"fps_std\"], axis=1, inplace=True)\n",
    "        X['rtt_std_log'] = X['rtt_std'].apply(lambda x: np.log(x) if x > 2 else x)\n",
    "        X.drop([\"dropped_frames_mean\"], axis=1, inplace=True)\n",
    "\n",
    "        if fit_mode:\n",
    "            X[\"target\"] = y\n",
    "\n",
    "            # dropping duplicates\n",
    "            X.drop_duplicates(inplace=True)\n",
    "\n",
    "            # dropping outliers\n",
    "            X = X.loc[X[\"rtt_std\"] < 1000]\n",
    "            X = X.loc[(X[\"fps_mean\"] < 80)]\n",
    "            X = X.loc[X[\"rtt_mean\"] < 600]\n",
    "\n",
    "        X.drop([\"dropped_frames_std\", 'dropped_frames_max'], inplace=True, axis=1)\n",
    "\n",
    "        if final:\n",
    "            X.drop([\"fps_unstable\"], inplace=True, axis=1)\n",
    "            X.drop([\"fps_std_log\"], inplace=True, axis=1)\n",
    "\n",
    "        if \"target\" in X.columns:\n",
    "            y = X[\"target\"]\n",
    "            X = X.drop(\"target\", axis=1)\n",
    "\n",
    "        if fit_mode:\n",
    "            self.scaler = MinMaxScaler().fit(X)\n",
    "        X = pd.DataFrame(self.scaler.transform(X), columns=X.columns, index=X.index)\n",
    "\n",
    "        if show_shapes:\n",
    "            print(f'Out data shape: {X.shape}')\n",
    "\n",
    "        if type(y) != bool:\n",
    "            return X, y\n",
    "        return X\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (379021, 9)\n",
      "Out data shape: (373472, 10)\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "_X_train = bitrate_reg_train.drop([\"target\"], axis=1)\n",
    "x_train_pipe, y_train = pipeline.regression_pipe(_X_train,\n",
    "                                                 bitrate_reg_train[\"target\"],\n",
    "                                                 fit_mode=True,\n",
    "                                                 final=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.10501965582705142\n",
      "root mean squared error: 5741.341937583855\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(fit_intercept=True).fit(x_train_pipe, y_train)\n",
    "y_train_pred_r = model.predict(x_train_pipe)\n",
    "\n",
    "print(f'r2_score: {r2_score(y_train, y_train_pred_r)}')\n",
    "print(f'root mean squared error: {mean_squared_error(y_train, y_train_pred_r, squared=False)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (379021, 9)\n",
      "Out data shape: (373472, 8)\n",
      "r2_score: 0.10501878388273789\n",
      "root mean squared error: 5741.344734365521\n"
     ]
    }
   ],
   "source": [
    "x_train_pipe, y_train_r = pipeline.regression_pipe(_X_train, bitrate_reg_train[\"target\"], fit_mode=True)\n",
    "\n",
    "model = LinearRegression(fit_intercept=True).fit(x_train_pipe, y_train_r)\n",
    "y_train_pred_r = model.predict(x_train_pipe)\n",
    "\n",
    "print(f'r2_score: {r2_score(y_train_r, y_train_pred_r)}')\n",
    "print(f'root mean squared error: {mean_squared_error(y_train_r, y_train_pred_r, squared=False)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (379021, 9)\n",
      "Out data shape: (373472, 8)\n",
      "{'r2_score': 0.10501878388273789, 'Root Squared Mean Error': 5741.344734365521}\n",
      "{'r2_score': 0.1050187838407517, 'Root Squared Mean Error': 5741.344734500192}\n",
      "{'r2_score': 0.10501878321155855, 'Root Squared Mean Error': 5741.344736518343}\n",
      "{'r2_score': 0.10501878182909763, 'Root Squared Mean Error': 5741.344740952618}\n",
      "{'r2_score': 0.10501877969539297, 'Root Squared Mean Error': 5741.344747796524}\n",
      "{'r2_score': 0.10501820609642343, 'Root Squared Mean Error': 5741.3465876278115}\n",
      "{'r2_score': 0.10500952822098619, 'Root Squared Mean Error': 5741.374422031873}\n",
      "{'r2_score': 0.10499032734673963, 'Root Squared Mean Error': 5741.436008618826}\n",
      "{'r2_score': 0.10496066774554791, 'Root Squared Mean Error': 5741.53114015579}\n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "    \"r2_score\" : r2_score,\n",
    "    \"Root Squared Mean Error\" : lambda x, y: mean_squared_error(x, y, squared=False)\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Simple Linear\" : LinearRegression(),\n",
    "    \"Ridge_0.1\" : Ridge(0.1),\n",
    "    \"Ridge_0.4\" : Ridge(0.4),\n",
    "    \"Ridge_0.7\" : Ridge(0.7),\n",
    "    \"Ridge_1.0\" : Ridge(1.0),\n",
    "    \"Lasso_0.1\" : Lasso(0.1),\n",
    "    \"Lasso_0.4\" : Lasso(0.4),\n",
    "    \"Lasso_0.7\" : Lasso(0.7),\n",
    "    \"Lasso_1.0\" : Lasso(1.0),\n",
    "}\n",
    "\n",
    "x_train_r_piped, y_train_r = pipeline.regression_pipe(bitrate_reg_train.drop(\"target\", axis=1), bitrate_reg_train[\"target\"], fit_mode=True)\n",
    "for n in models:\n",
    "    scores = evaluate_model(models[n], x_train_r_piped, y_train_r, metrics=metrics, fit_model=True)[0]\n",
    "    print(scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (379021, 9)\n",
      "Out data shape: (373472, 8)\n",
      "{'r2_score': 0.105018783882738, 'Root Squared Mean Error': 5741.34473436552, 'Mean Absolute Error': 4443.309825613737}\n",
      "{'r2_score': 0.12825060571056524, 'Root Squared Mean Error': 5666.338190367393, 'Mean Absolute Error': 4363.889152009785}\n",
      "{'r2_score': 0.1423409998792613, 'Root Squared Mean Error': 5620.35812003486, 'Mean Absolute Error': 4306.682076511484}\n",
      "{'r2_score': 0.15603390440894138, 'Root Squared Mean Error': 5575.311851549453, 'Mean Absolute Error': 4255.82257539302}\n",
      "{'r2_score': 0.16558648722429947, 'Root Squared Mean Error': 5543.669471728776, 'Mean Absolute Error': 4233.406325885124}\n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "    \"r2_score\": r2_score,\n",
    "    \"Root Squared Mean Error\": lambda x, y: mean_squared_error(x, y, squared=False),\n",
    "    \"Mean Absolute Error\": mean_absolute_error\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Poly_1\": Polynomial(1),\n",
    "    \"Poly_2\": Polynomial(2),\n",
    "    \"Poly_3\": Polynomial(3),\n",
    "    \"Poly_4\": Polynomial(4),\n",
    "    \"Poly_5\": Polynomial(5)\n",
    "}\n",
    "\n",
    "x_train_r_piped, y_train_r = pipeline.regression_pipe(bitrate_reg_train.drop(\"target\", axis=1),\n",
    "                                                      bitrate_reg_train[\"target\"], fit_mode=True)\n",
    "for n in models:\n",
    "    scores = evaluate_model(models[n], x_train_r_piped, y_train_r, metrics=metrics, fit_model=True)[0]\n",
    "    print(scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    def __init__(self):\n",
    "        self.scaler_c = None\n",
    "        self.pca_c = None\n",
    "\n",
    "    def class_pipeline(self, X_, y=False, fit_mode=False, final=True, show_shapes=False, with_pca=False):\n",
    "        X = X_.copy()\n",
    "\n",
    "        if show_shapes:\n",
    "            print(f\"Input shape: {X.shape}\")\n",
    "\n",
    "        # dropping features highly correlated with other features\n",
    "        X.drop([\"dropped_frames_max\"], inplace=True, axis=1)\n",
    "\n",
    "        # encoding categorical features\n",
    "        X[\"auto_bitrate_state\"] = X[\"auto_bitrate_state\"].apply(lambda x: x != \"off\")\n",
    "        X[\"auto_fec_state\"] = X[\"auto_fec_state\"].apply(lambda x: x != \"off\")\n",
    "\n",
    "        # adding binary features\n",
    "        X['dropped_frames_occured'] = X['dropped_frames_mean'].apply(lambda x: np.int8(x > 0))\n",
    "        X['fps_unstable'] = X['fps_std'].apply(lambda x: x > 5)\n",
    "        X['rtt_unstable'] = X['rtt_std'].apply(lambda x: x > 5)\n",
    "        X['fps_anomaly'] = X['fps_mean'].apply(lambda x: not (20 < x < 30))\n",
    "        X['rtt_anomaly'] = X['rtt_mean'].apply(lambda x: x > 50)\n",
    "        X['fps_lag_huge'] = X['fps_lags'].apply(lambda x: x > 2)\n",
    "        X['auto_fec_mean_high'] = X['auto_fec_mean'].apply(lambda x: x > 50)\n",
    "\n",
    "        if fit_mode:\n",
    "            X[\"stream_quality\"] = y\n",
    "            X.drop_duplicates(inplace=True)\n",
    "\n",
    "            X = X.loc[X[\"fps_std\"] < 30]\n",
    "            X = X.loc[X[\"fps_mean\"] < 80]\n",
    "            X = X.loc[X[\"rtt_mean\"] < 600]\n",
    "            X = X.loc[X[\"rtt_std\"] < 1000]\n",
    "            X = X.loc[X[\"dropped_frames_std\"] < 100]\n",
    "\n",
    "        if final:\n",
    "            X.drop([\"dropped_frames_mean\"], axis=1, inplace=True)\n",
    "            X.drop([\"rtt_unstable\"], axis=1, inplace=True)\n",
    "\n",
    "        features_pca = [\"fps_unstable\", \"fps_anomaly\", \"rtt_anomaly\", \"fps_lag_huge\", \"auto_fec_mean_high\",\n",
    "                        \"dropped_frames_std\", \"auto_bitrate_state\", \"auto_fec_state\", \"auto_fec_mean\"]\n",
    "\n",
    "        if with_pca and fit_mode:\n",
    "            self.pca_c = PCA(1).fit(X[features_pca])\n",
    "\n",
    "        if with_pca:\n",
    "            X[\"Other_feats\"] = self.pca_c.transform(X[features_pca])\n",
    "            X.drop(features_pca, axis=1, inplace=True)\n",
    "\n",
    "        if \"stream_quality\" in X.columns:\n",
    "            y = X[\"stream_quality\"]\n",
    "            X.drop(\"stream_quality\", axis=1, inplace=True)\n",
    "\n",
    "        if fit_mode:\n",
    "            self.scaler_c = MinMaxScaler().fit(X)\n",
    "\n",
    "        X = pd.DataFrame(self.scaler_c.transform(X), columns=X.columns, index=X.index)\n",
    "\n",
    "        if show_shapes:\n",
    "            print(f\"Output shape: {X.shape}\")\n",
    "\n",
    "        if type(y) != bool:\n",
    "            return X, y\n",
    "        return X\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (406572, 11)\n",
      "Output shape: (371028, 15)\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "x_train_c_piped, y_train_c = pipeline.class_pipeline(stream_class_train.drop(\"stream_quality\", axis=1),\n",
    "                                                     stream_class_train[\"stream_quality\"], fit_mode=True,\n",
    "                                                     show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "                               0\nfps_mean               -2.499149\nfps_std                 1.628067\nfps_lags                5.498069\nrtt_mean                0.439947\nrtt_std                 1.141372\ndropped_frames_std      0.518376\nauto_bitrate_state      0.235656\nauto_fec_state          0.594924\nauto_fec_mean          -0.359755\ndropped_frames_occured  1.027400\nfps_unstable            0.070244\nfps_anomaly             0.426052\nrtt_anomaly             0.241278\nfps_lag_huge           -0.315028\nauto_fec_mean_high      0.206210",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>fps_mean</th>\n      <td>-2.499149</td>\n    </tr>\n    <tr>\n      <th>fps_std</th>\n      <td>1.628067</td>\n    </tr>\n    <tr>\n      <th>fps_lags</th>\n      <td>5.498069</td>\n    </tr>\n    <tr>\n      <th>rtt_mean</th>\n      <td>0.439947</td>\n    </tr>\n    <tr>\n      <th>rtt_std</th>\n      <td>1.141372</td>\n    </tr>\n    <tr>\n      <th>dropped_frames_std</th>\n      <td>0.518376</td>\n    </tr>\n    <tr>\n      <th>auto_bitrate_state</th>\n      <td>0.235656</td>\n    </tr>\n    <tr>\n      <th>auto_fec_state</th>\n      <td>0.594924</td>\n    </tr>\n    <tr>\n      <th>auto_fec_mean</th>\n      <td>-0.359755</td>\n    </tr>\n    <tr>\n      <th>dropped_frames_occured</th>\n      <td>1.027400</td>\n    </tr>\n    <tr>\n      <th>fps_unstable</th>\n      <td>0.070244</td>\n    </tr>\n    <tr>\n      <th>fps_anomaly</th>\n      <td>0.426052</td>\n    </tr>\n    <tr>\n      <th>rtt_anomaly</th>\n      <td>0.241278</td>\n    </tr>\n    <tr>\n      <th>fps_lag_huge</th>\n      <td>-0.315028</td>\n    </tr>\n    <tr>\n      <th>auto_fec_mean_high</th>\n      <td>0.206210</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression().fit(x_train_c_piped, y_train_c)\n",
    "pd.DataFrame(model.coef_, columns=x_train_c_piped.columns).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "                               0\nfps_mean               -1.689172\nfps_std                 1.877139\nfps_lags                5.795160\nrtt_mean                1.141644\nrtt_std                 0.723113\ndropped_frames_occured  1.089065\nOther_feats             0.485232",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>fps_mean</th>\n      <td>-1.689172</td>\n    </tr>\n    <tr>\n      <th>fps_std</th>\n      <td>1.877139</td>\n    </tr>\n    <tr>\n      <th>fps_lags</th>\n      <td>5.795160</td>\n    </tr>\n    <tr>\n      <th>rtt_mean</th>\n      <td>1.141644</td>\n    </tr>\n    <tr>\n      <th>rtt_std</th>\n      <td>0.723113</td>\n    </tr>\n    <tr>\n      <th>dropped_frames_occured</th>\n      <td>1.089065</td>\n    </tr>\n    <tr>\n      <th>Other_feats</th>\n      <td>0.485232</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_c_piped, y_train_c = pipeline.class_pipeline(stream_class_train.drop(\"stream_quality\", axis=1),\n",
    "                                                     stream_class_train[\"stream_quality\"], fit_mode=True, with_pca=True)\n",
    "model = LogisticRegression().fit(x_train_c_piped, y_train_c)\n",
    "pd.DataFrame(model.coef_, columns=x_train_c_piped.columns).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.8840141444850523\n",
      "precision score: 0.9194280000785652\n",
      "recall score: 0.8840141444850523\n",
      "f1_score score: 0.8991843629006989\n",
      "precision score unweighted: 0.2578346892600972\n"
     ]
    }
   ],
   "source": [
    "x = x_train_c_piped\n",
    "y = y_train_c\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, class_weight=\"balanced\").fit(x_train_c_piped, y_train_c)\n",
    "y_pred = model.predict_proba(x)[:,0] < threshold\n",
    "\n",
    "print(f'accuracy score: {accuracy_score(y_train_c, y_pred)}')\n",
    "print(f'precision score: {precision_score(y_train_c, y_pred, average=\"weighted\")}')\n",
    "print(f'recall score: {recall_score(y_train_c, y_pred, average=\"weighted\")}')\n",
    "print(f'f1_score score: {f1_score(y_train_c, y_pred, average=\"weighted\")}')\n",
    "print(f'precision score unweighted: {precision_score(y_train_c, y_pred)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy score': 0.9005907932666293, 'precision weighted score': 0.9231406030372495, 'recall_score': 0.5430768125314364, 'f1_score': 0.4279183003297994}\n",
      "{'accuracy score': 0.8923610086282381, 'precision weighted score': 0.9216657993618442, 'recall_score': 0.5502263418840267, 'f1_score': 0.41173228663987205}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bekhruz/miniconda3/envs/colab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy score': 0.8867310095136901, 'precision weighted score': 0.9225636131011863, 'recall_score': 0.5766328950204785, 'f1_score': 0.4107380489302897}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bekhruz/miniconda3/envs/colab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy score': 0.884704308216011, 'precision weighted score': 0.9227763160275648, 'recall_score': 0.5843931881871093, 'f1_score': 0.4096816441668346}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [95], line 28\u001B[0m\n\u001B[1;32m     23\u001B[0m x_test_c_piped, y_test_c \u001B[38;5;241m=\u001B[39m pipeline\u001B[38;5;241m.\u001B[39mclass_pipeline(stream_class_train\u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream_quality\u001B[39m\u001B[38;5;124m\"\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m),\n\u001B[1;32m     24\u001B[0m                                                    stream_class_train[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream_quality\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     25\u001B[0m                                                    with_pca\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m models_final:\n\u001B[0;32m---> 28\u001B[0m     scores \u001B[38;5;241m=\u001B[39m evaluate_model(models_final[n], x_train_c_piped, y_train_c, x_test_c_piped, y_test_c, fit_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     29\u001B[0m                             metrics\u001B[38;5;241m=\u001B[39mmetrics)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28mprint\u001B[39m(scores)\n",
      "Cell \u001B[0;32mIn [83], line 17\u001B[0m, in \u001B[0;36mevaluate_model\u001B[0;34m(model, x_train, y_train, x_test, y_test, metrics, fit_model)\u001B[0m\n\u001B[1;32m     14\u001B[0m     y_test \u001B[38;5;241m=\u001B[39m y_train\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fit_model:\n\u001B[0;32m---> 17\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(x_test)\n\u001B[1;32m     21\u001B[0m scores \u001B[38;5;241m=\u001B[39m {}\n",
      "Cell \u001B[0;32mIn [84], line 29\u001B[0m, in \u001B[0;36mPolynomial.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y):\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpoly_transform \u001B[38;5;241m=\u001B[39m PolynomialFeatures(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdegree)\u001B[38;5;241m.\u001B[39mfit(X)\n\u001B[0;32m---> 29\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoly_transform\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn [84], line 7\u001B[0m, in \u001B[0;36mClassifier.fit\u001B[0;34m(self, x, y)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, y):\n\u001B[0;32m----> 7\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1233\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1230\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1231\u001B[0m     n_threads \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1233\u001B[0m fold_coefs_ \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprefer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1234\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1235\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1236\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1237\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1238\u001B[0m \u001B[43m        \u001B[49m\u001B[43mCs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mC_\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1239\u001B[0m \u001B[43m        \u001B[49m\u001B[43ml1_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ml1_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1240\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_intercept\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_intercept\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1241\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1242\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1243\u001B[0m \u001B[43m        \u001B[49m\u001B[43msolver\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1244\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1245\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1246\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1247\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1248\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1249\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcoef\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwarm_start_coef_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1250\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpenalty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpenalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1251\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_squared_sum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_squared_sum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1252\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1253\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_threads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_threads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1254\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1255\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mclass_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarm_start_coef_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mclasses_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarm_start_coef\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1256\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1258\u001B[0m fold_coefs_, _, n_iter_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mfold_coefs_)\n\u001B[1;32m   1259\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_iter_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(n_iter_, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mint32)[:, \u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/joblib/parallel.py:1085\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1077\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n\u001B[1;32m   1078\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1082\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n\u001B[1;32m   1083\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n\u001B[1;32m   1084\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 1085\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1086\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1088\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/joblib/parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 901\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/joblib/parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[1;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[1;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/sklearn/utils/fixes.py:117\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[0;32m--> 117\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:436\u001B[0m, in \u001B[0;36m_logistic_regression_path\u001B[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001B[0m\n\u001B[1;32m    432\u001B[0m l2_reg_strength \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m C\n\u001B[1;32m    433\u001B[0m iprint \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m50\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m101\u001B[39m][\n\u001B[1;32m    434\u001B[0m     np\u001B[38;5;241m.\u001B[39msearchsorted(np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m]), verbose)\n\u001B[1;32m    435\u001B[0m ]\n\u001B[0;32m--> 436\u001B[0m opt_res \u001B[38;5;241m=\u001B[39m \u001B[43moptimize\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    437\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    438\u001B[0m \u001B[43m    \u001B[49m\u001B[43mw0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    439\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mL-BFGS-B\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    440\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    441\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ml2_reg_strength\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_threads\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    442\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43miprint\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43miprint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgtol\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaxiter\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    444\u001B[0m n_iter_i \u001B[38;5;241m=\u001B[39m _check_optimize_result(\n\u001B[1;32m    445\u001B[0m     solver,\n\u001B[1;32m    446\u001B[0m     opt_res,\n\u001B[1;32m    447\u001B[0m     max_iter,\n\u001B[1;32m    448\u001B[0m     extra_warning_msg\u001B[38;5;241m=\u001B[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001B[1;32m    449\u001B[0m )\n\u001B[1;32m    450\u001B[0m w0, loss \u001B[38;5;241m=\u001B[39m opt_res\u001B[38;5;241m.\u001B[39mx, opt_res\u001B[38;5;241m.\u001B[39mfun\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/scipy/optimize/_minimize.py:699\u001B[0m, in \u001B[0;36mminimize\u001B[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[1;32m    696\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001B[1;32m    697\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml-bfgs-b\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 699\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43m_minimize_lbfgsb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    700\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    701\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtnc\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    702\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[1;32m    703\u001B[0m                         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py:362\u001B[0m, in \u001B[0;36m_minimize_lbfgsb\u001B[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001B[0m\n\u001B[1;32m    356\u001B[0m task_str \u001B[38;5;241m=\u001B[39m task\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[1;32m    357\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFG\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    358\u001B[0m     \u001B[38;5;66;03m# The minimization routine wants f and g at the current x.\u001B[39;00m\n\u001B[1;32m    359\u001B[0m     \u001B[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001B[39;00m\n\u001B[1;32m    360\u001B[0m     \u001B[38;5;66;03m# until the completion of the current minimization iteration.\u001B[39;00m\n\u001B[1;32m    361\u001B[0m     \u001B[38;5;66;03m# Overwrite f and g:\u001B[39;00m\n\u001B[0;32m--> 362\u001B[0m     f, g \u001B[38;5;241m=\u001B[39m \u001B[43mfunc_and_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    363\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNEW_X\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    364\u001B[0m     \u001B[38;5;66;03m# new iteration\u001B[39;00m\n\u001B[1;32m    365\u001B[0m     n_iterations \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:285\u001B[0m, in \u001B[0;36mScalarFunction.fun_and_grad\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray_equal(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx):\n\u001B[1;32m    284\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_x_impl(x)\n\u001B[0;32m--> 285\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_grad()\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:251\u001B[0m, in \u001B[0;36mScalarFunction._update_fun\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_fun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    250\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated:\n\u001B[0;32m--> 251\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    252\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:155\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.update_fun\u001B[0;34m()\u001B[0m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_fun\u001B[39m():\n\u001B[0;32m--> 155\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[43mfun_wrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:137\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnfev \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;66;03m# Send a copy because the user may overwrite it.\u001B[39;00m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;66;03m# Overwriting results in undefined behaviour because\u001B[39;00m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001B[39;00m\n\u001B[0;32m--> 137\u001B[0m fx \u001B[38;5;241m=\u001B[39m \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;66;03m# Make sure the function returns a true scalar\u001B[39;00m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misscalar(fx):\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/scipy/optimize/_optimize.py:76\u001B[0m, in \u001B[0;36mMemoizeJac.__call__\u001B[0;34m(self, x, *args)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39margs):\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;124;03m\"\"\" returns the the function value \"\"\"\u001B[39;00m\n\u001B[0;32m---> 76\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_if_needed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/scipy/optimize/_optimize.py:70\u001B[0m, in \u001B[0;36mMemoizeJac._compute_if_needed\u001B[0;34m(self, x, *args)\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(x \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x)\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m---> 70\u001B[0m     fg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:187\u001B[0m, in \u001B[0;36mLinearModelLoss.loss_gradient\u001B[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads)\u001B[0m\n\u001B[1;32m    185\u001B[0m n_features, n_classes \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_loss\u001B[38;5;241m.\u001B[39mn_classes\n\u001B[1;32m    186\u001B[0m n_dof \u001B[38;5;241m=\u001B[39m n_features \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_intercept)\n\u001B[0;32m--> 187\u001B[0m weights, intercept, raw_prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_w_intercept_raw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcoef\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m loss, grad_per_sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_loss\u001B[38;5;241m.\u001B[39mloss_gradient(\n\u001B[1;32m    190\u001B[0m     y_true\u001B[38;5;241m=\u001B[39my,\n\u001B[1;32m    191\u001B[0m     raw_prediction\u001B[38;5;241m=\u001B[39mraw_prediction,\n\u001B[1;32m    192\u001B[0m     sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[1;32m    193\u001B[0m     n_threads\u001B[38;5;241m=\u001B[39mn_threads,\n\u001B[1;32m    194\u001B[0m )\n\u001B[1;32m    195\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39msum()\n",
      "File \u001B[0;32m~/miniconda3/envs/colab/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:99\u001B[0m, in \u001B[0;36mLinearModelLoss._w_intercept_raw\u001B[0;34m(self, coef, X)\u001B[0m\n\u001B[1;32m     97\u001B[0m         intercept \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m     98\u001B[0m         weights \u001B[38;5;241m=\u001B[39m coef\n\u001B[0;32m---> 99\u001B[0m     raw_prediction \u001B[38;5;241m=\u001B[39m \u001B[43mX\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m \u001B[38;5;241m+\u001B[39m intercept\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;66;03m# reshape to (n_classes, n_dof)\u001B[39;00m\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m coef\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "threshold = 0.45\n",
    "\n",
    "models_final = {\n",
    "    \"Logistic_l2\": Classifier(LogisticRegression(penalty=\"l2\", max_iter=100, class_weight='balanced'), threshold),\n",
    "    \"Ridge\": RidgeClassifier(max_iter=100, class_weight='balanced'),\n",
    "    \"Polynomial_d4\": Polynomial(4, estimator=Classifier(LogisticRegression(max_iter=100, class_weight='balanced'),\n",
    "                                                        threshold)),\n",
    "    \"Polynomial_d5\": Polynomial(5, estimator=Classifier(LogisticRegression(max_iter=100, class_weight='balanced'),\n",
    "                                                        threshold)),\n",
    "    \"Polynomial_d7\": Polynomial(7, estimator=Classifier(LogisticRegression(max_iter=100, class_weight='balanced'),\n",
    "                                                        threshold - 0.1))\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy score\": lambda x, y: accuracy_score(x, y),\n",
    "    \"precision weighted score\": lambda x, y: precision_score(x, y, average=\"weighted\"),\n",
    "    \"recall_score\": lambda x, y: recall_score(x, y),\n",
    "    \"f1_score\": lambda x, y: f1_score(x, y)\n",
    "}\n",
    "\n",
    "x_test_c_piped, y_test_c = pipeline.class_pipeline(stream_class_train.drop(\"stream_quality\", axis=1),\n",
    "                                                   stream_class_train[\"stream_quality\"],\n",
    "                                                   with_pca=True)\n",
    "\n",
    "for n in models_final:\n",
    "    scores = evaluate_model(models_final[n], x_train_c_piped, y_train_c, x_test_c_piped, y_test_c, fit_model=True,\n",
    "                            metrics=metrics)[0]\n",
    "    print(scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bfb770074c8a5b7b3084520ecd9fe0f0e8d46aea139fbf46f675525725d70b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
